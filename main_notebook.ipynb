{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x22fa8ea58f0>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 315
    }
   ],
   "source": [
    "# basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "# demos for visualization\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting\n",
    "from nilearn.connectome import GroupSparseCovariance\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for ML\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn import ensemble\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# os library\n",
    "from os.path import exists, join\n",
    "\n",
    "np.random.seed(1679838)\n",
    "torch.manual_seed(1679838)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "blessed-register",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-28T09:53:27.478513Z",
     "iopub.status.busy": "2021-06-28T09:53:27.474676Z",
     "iopub.status.idle": "2021-06-28T09:53:35.422989Z",
     "shell.execute_reply": "2021-06-28T09:53:35.421589Z",
     "shell.execute_reply.started": "2021-06-28T06:49:00.608859Z"
    },
    "papermill": {
     "duration": 7.970231,
     "end_time": "2021-06-28T09:53:35.423239",
     "exception": false,
     "start_time": "2021-06-28T09:53:27.453008",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_path = join(\".\", \"data\") if exists(join(\".\", \"data\")) \\\n",
    "    else join(\"..\", \"input\", \"statistical-learning-sapienza-spring-2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "train = pd.read_csv(join(data_path, 'train.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "outputs": [],
   "source": [
    "roi_indices = ['Frontal' in x for x in pd.read_csv(join('.', 'data', 'coordinates.txt'), sep = ' ')['Abbreviation']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Precentral_L', 'Precentral_R', 'Frontal_Sup_L', 'Frontal_Sup_R',\n       'Frontal_Sup_Orb_L', 'Frontal_Sup_Orb_R', 'Frontal_Mid_L',\n       'Frontal_Mid_R', 'Frontal_Mid_Orb_L', 'Frontal_Mid_Orb_R',\n       'Frontal_Inf_Oper_L', 'Frontal_Inf_Oper_R', 'Frontal_Inf_Tri_L',\n       'Frontal_Inf_Tri_R', 'Frontal_Inf_Orb_L', 'Frontal_Inf_Orb_R',\n       'Rolandic_Oper_L', 'Rolandic_Oper_R', 'Supp_Motor_Area_L',\n       'Supp_Motor_Area_R', 'Olfactory_L', 'Olfactory_R',\n       'Frontal_Sup_Medial_L', 'Frontal_Sup_Medial_R',\n       'Frontal_Med_Orb_L', 'Frontal_Med_Orb_R', 'Rectus_L', 'Rectus_R',\n       'Insula_L', 'Insula_R', 'Cingulum_Ant_L', 'Cingulum_Ant_R',\n       'Cingulum_Mid_L', 'Cingulum_Mid_R', 'Cingulum_Post_L',\n       'Cingulum_Post_R', 'Hippocampus_L', 'Hippocampus_R',\n       'ParaHippocampal_L', 'ParaHippocampal_R', 'Amygdala_L',\n       'Amygdala_R', 'Calcarine_L', 'Calcarine_R', 'Cuneus_L', 'Cuneus_R',\n       'Lingual_L', 'Lingual_R', 'Occipital_Sup_L', 'Occipital_Sup_R',\n       'Occipital_Mid_L', 'Occipital_Mid_R', 'Occipital_Inf_L',\n       'Occipital_Inf_R', 'Fusiform_L', 'Fusiform_R', 'Postcentral_L',\n       'Postcentral_R', 'Parietal_Sup_L', 'Parietal_Sup_R',\n       'Parietal_Inf_L', 'Parietal_Inf_R', 'SupraMarginal_L',\n       'SupraMarginal_R', 'Angular_L', 'Angular_R', 'Precuneus_L',\n       'Precuneus_R', 'Paracentral_Lobule_L', 'Paracentral_Lobule_R',\n       'Caudate_L', 'Caudate_R', 'Putamen_L', 'Putamen_R', 'Pallidum_L',\n       'Pallidum_R', 'Thalamus_L', 'Thalamus_R', 'Heschl_L', 'Heschl_R',\n       'Temporal_Sup_L', 'Temporal_Sup_R', 'Temporal_Pole_Sup_L',\n       'Temporal_Pole_Sup_R', 'Temporal_Mid_L', 'Temporal_Mid_R',\n       'Temporal_Pole_Mid_L', 'Temporal_Pole_Mid_R', 'Temporal_Inf_L',\n       'Temporal_Inf_R', 'Cerebellum_Crus1_L', 'Cerebellum_Crus1_R',\n       'Cerebellum_Crus2_L', 'Cerebellum_Crus2_R', 'Cerebellum_3_L',\n       'Cerebellum_3_R', 'Cerebellum_4_5_L', 'Cerebellum_4_5_R',\n       'Cerebellum_6_L', 'Cerebellum_6_R', 'Cerebellum_7b_L',\n       'Cerebellum_7b_R', 'Cerebellum_8_L', 'Cerebellum_8_R',\n       'Cerebellum_9_L', 'Cerebellum_9_R', 'Cerebellum_10_L',\n       'Cerebellum_10_R', 'Vermis_1_2', 'Vermis_3', 'Vermis_4_5',\n       'Vermis_6', 'Vermis_7', 'Vermis_8', 'Vermis_9', 'Vermis_10'],\n      dtype=object)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 428
    }
   ],
   "source": [
    "pd.read_csv(join('.', 'data', 'coordinates.txt'), sep = ' ')['Abbreviation'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "outputs": [],
   "source": [
    "y_train = train.loc[:,'y']\n",
    "X_train = train.drop(columns=['y'])\n",
    "X_train.loc[:, 'var2'] = X_train.loc[:, 'var2'] == 'A'\n",
    "X_train.loc[:, 'var3'] = X_train.loc[:, 'var3'] == 'A'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "outputs": [
    {
     "data": {
      "text/plain": "PCA(n_components=0.9, svd_solver='full')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 430
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "mean_ts_train = X_train.iloc[:,4:].apply(np.mean, axis=0).to_numpy().reshape(115, 116)\n",
    "pca_model = PCA(n_components=0.9, svd_solver='full')\n",
    "pca_model.fit(mean_ts_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "outputs": [],
   "source": [
    "def get_data(entry):\n",
    "    variables = entry[['var1', 'var2', 'var3']].to_numpy()\n",
    "    timeseries = entry[5 if \"y\" in entry.index else 4:].to_numpy(dtype=float).reshape((115, 116), order=\"F\")\n",
    "    # timeseries = timeseries[:, roi_indices]\n",
    "    return {\"variables\": variables, \"timeseries\": timeseries}\n",
    "\n",
    "train_timeseries = X_train.apply(lambda row: pca_model.transform(get_data(row)[\"timeseries\"]), axis=1).to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "variables = train[['var1', 'var2', 'var3']]\n",
    "variables.loc[:, 'var2'] = vars.loc[:, 'var2'] == 'A'\n",
    "variables.loc[:, 'var3'] = vars.loc[:, 'var3'] == 'A'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correlation matrices and PCA\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.0% done in 0.0 seconds\n",
      "10.0% done in 21.56 seconds\n",
      "20.0% done in 45.86 seconds\n",
      "30.0% done in 67.25 seconds\n",
      "40.0% done in 88.82 seconds\n",
      "50.0% done in 110.86 seconds\n",
      "60.0% done in 132.42 seconds\n",
      "70.0% done in 154.43 seconds\n",
      "80.0% done in 175.19 seconds\n",
      "90.0% done in 198.22 seconds\n",
      "Granger Analysis done in 3.66 minutes\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\nitime\\algorithms\\autoregressive.py:523: RuntimeWarning: invalid value encountered in log\n",
      "  f_xy = np.log(f_xy)\n",
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\nitime\\algorithms\\autoregressive.py:509: RuntimeWarning: invalid value encountered in log\n",
      "  f_x_on_y = np.log(Syy.real / yy_auto_component)\n",
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\nitime\\algorithms\\autoregressive.py:499: RuntimeWarning: invalid value encountered in log\n",
      "  f_y_on_x = np.log(Sxx.real / xx_auto_component)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import nitime.timeseries as ts\n",
    "time_series = list(map(lambda x: ts.TimeSeries(x.T, sampling_interval=1), train_timeseries))\n",
    "\n",
    "import nitime.analysis as nta\n",
    "import time\n",
    "start = time.time()\n",
    "f_ub = 0.15\n",
    "f_lb = 0.02\n",
    "causalities = []\n",
    "for i, x in enumerate(time_series):\n",
    "    if i%60 == 0:\n",
    "        print(f'{i/6}% done in {round(time.time() - start, 2)} seconds')\n",
    "    G=nta.GrangerAnalyzer(x, order=1)\n",
    "    freq_idx_G = np.where((G.frequencies > f_lb) * (G.frequencies < f_ub))[0]\n",
    "    g1 = np.mean(G.causality_xy[:, :, freq_idx_G], -1)\n",
    "    causalities.append(g1)\n",
    "print(f'Granger Analysis done in {round((time.time() - start)/60, 2)} minutes')\n",
    "\n",
    "for c in causalities:\n",
    "    c[np.isnan(c)] = 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "outputs": [],
   "source": [
    "X_train = np.hstack([variables, np.vstack(list(map(lambda x: np.abs(x.flatten())>0.25, causalities)))])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[19, False, False, ..., False, False, False],\n       [14, False, False, ..., False, False, False],\n       [13, False, False, ..., False, False, False],\n       ...,\n       [27, False, False, ..., False, False, False],\n       [29, False, False, ..., False, False, False],\n       [26, False, False, ..., False, False, False]], dtype=object)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 435
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [],
   "source": [
    "# def apply_connectivity(time_series, vect=True, diag=True):\n",
    "#     # objects:\n",
    "#     correlation_measure = ConnectivityMeasure(kind='partial correlation',\n",
    "#                                               vectorize = vect,\n",
    "#                                               discard_diagonal=diag)\n",
    "#     \n",
    "#     \n",
    "# \n",
    "#     # fitting predicting:\n",
    "#     return correlation_measure.fit_transform(time_series)\n",
    "#     # pca_model.fit(cor_mat)\n",
    "# \n",
    "# train_cor_vec = apply_connectivity(train_timeseries)\n",
    "# val_cor_vec = apply_connectivity(val_timeseries)\n",
    "# \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "best params: {'shrinking': True, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2, 'C': 0.1}\n",
      "best score: -14.632556842843966\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#model \n",
    "model = svm.SVR(max_iter=10000)\n",
    "#cross validation with random search model\n",
    "params = dict(kernel=['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "              degree=[2,3,4],\n",
    "              C=[0.1, 0.5, 1.0, 1.5, 2, 3, 5, 10, 30, 50],\n",
    "              gamma= ['auto', 'scale'],\n",
    "              shrinking = [True, False]\n",
    "             )\n",
    "reg = RandomizedSearchCV(estimator = model, param_distributions = params,\n",
    "                                   scoring = 'neg_root_mean_squared_error',\n",
    "                                   n_iter = 150,\n",
    "                                   cv = 4, n_jobs = -1)\n",
    "random_search = reg.fit(X_train, y_train)\n",
    "\n",
    "print(f'best params: {random_search.best_params_}')\n",
    "print(f'best score: {random_search.best_score_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "best train score -14.701335639866363\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_train)\n",
    "print(f'best train score {-mean_squared_error(y_train, y_pred, squared=False)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "outputs": [],
   "source": [
    "test = pd.read_csv(join('.', 'data', 'test.csv'))\n",
    "test.loc[:, 'var2'] = test.loc[:, 'var2'] == 'A'\n",
    "test.loc[:, 'var3'] = test.loc[:, 'var3'] == 'A'\n",
    "\n",
    "test_timeseries = test.apply(lambda row: pca_model.transform(get_data(row)[\"timeseries\"]), axis=1).to_list()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "outputs": [
    {
     "data": {
      "text/plain": "(115, 18)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 414
    }
   ],
   "source": [
    "test_timeseries[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.0% done in 0.0 seconds\n",
      "10.0% done in 21.68 seconds\n",
      "20.0% done in 45.04 seconds\n",
      "30.0% done in 65.62 seconds\n",
      "Granger Analysis done in 1.21 minutes\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\nitime\\algorithms\\autoregressive.py:523: RuntimeWarning: invalid value encountered in log\n",
      "  f_xy = np.log(f_xy)\n",
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\nitime\\algorithms\\autoregressive.py:499: RuntimeWarning: invalid value encountered in log\n",
      "  f_y_on_x = np.log(Sxx.real / xx_auto_component)\n",
      "C:\\Users\\simon\\Anaconda3\\lib\\site-packages\\nitime\\algorithms\\autoregressive.py:509: RuntimeWarning: invalid value encountered in log\n",
      "  f_x_on_y = np.log(Syy.real / yy_auto_component)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_timeseries = list(map(lambda x: ts.TimeSeries(x.T, sampling_interval=1), test_timeseries))\n",
    "\n",
    "start = time.time()\n",
    "f_ub = 0.15\n",
    "f_lb = 0.02\n",
    "test_causalities = []\n",
    "for i, x in enumerate(test_timeseries):\n",
    "    if i%60 == 0:\n",
    "        print(f'{i/6}% done in {round(time.time() - start, 2)} seconds')\n",
    "    G=nta.GrangerAnalyzer(x, order=1)\n",
    "    freq_idx_G = np.where((G.frequencies > f_lb) * (G.frequencies < f_ub))[0]\n",
    "    g1 = np.mean(G.causality_xy[:, :, freq_idx_G], -1)\n",
    "    test_causalities.append(g1)\n",
    "print(f'Granger Analysis done in {round((time.time() - start)/60, 2)} minutes')\n",
    "\n",
    "for c in test_causalities:\n",
    "    c[np.isnan(c)] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "outputs": [],
   "source": [
    "X_test = np.hstack([test[['var1', 'var2', 'var3']], np.vstack(list(map(lambda x: np.abs(x.flatten())>0.25, test_causalities)))])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "outputs": [],
   "source": [
    "\n",
    "prediction = best_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.Series(prediction, name='target')], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "outputs": [],
   "source": [
    "submission.to_csv('submission_granger_pca.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "train_var_and_cor = pd.concat([pd.DataFrame(train_variables).add_prefix('var_'), train_cor_vec], axis=1)\n",
    "val_var_and_cor = pd.concat([pd.DataFrame(val_variables).add_prefix('var_'), val_cor_vec], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data loaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def get_dataloader(timeseries, variables_correlation, labels):\n",
    "    return DataLoader(TensorDataset(torch.Tensor(timeseries),torch.Tensor(variables_correlation),\n",
    "                                    torch.Tensor(labels)), batch_size=10) # create your dataloader\n",
    "\n",
    "train_dataloader = get_dataloader(train_timeseries, np.array(train_variables), train_split.y.to_numpy())\n",
    "val_dataloader = get_dataloader(val_timeseries, np.array(val_variables), val_split.y.to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "class BlackEmbedding(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.rnn_model = nn.RNN(input_size=119, hidden_size=hidden_size, num_layers=num_layers, dropout=0.05, batch_first=True)\n",
    "        self.fc1 = nn.Linear(3+(hidden_size*(1+num_layers)), 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.regressor = nn.Linear(32, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, var_and_cor, predict_anyway=False):\n",
    "        x = torch.cat([x, np.repeat(var_and_cor[:, np.newaxis,:], 115, axis=1)], dim=-1)\n",
    "        outputs, hidden = self.rnn_model(x)\n",
    "\n",
    "        hidden = torch.cat(list(map(lambda i: hidden[i, ], range(hidden.shape[0]))), dim=-1)\n",
    "\n",
    "        x = torch.cat([var_and_cor, outputs[:, -1, ], hidden], dim=-1)  # taking only the last\n",
    "\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "\n",
    "        if self.training or predict_anyway:\n",
    "            x = self.regressor(x)\n",
    "\n",
    "        return x.squeeze(dim=1)\n",
    "\n",
    "model = BlackEmbedding(hidden_size=64, num_layers=5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0007)\n",
    "criterion = nn.MSELoss()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\n",
      "------> Epoch 1 <------\n",
      "    Train RMSE loss: 14.134319305419922\n",
      "    Val   RMSE loss: 15.566473007202148\n",
      "\n",
      "------> Epoch 2 <------\n",
      "    Train RMSE loss: 14.133048057556152\n",
      "    Val   RMSE loss: 15.513832092285156\n",
      "\n",
      "------> Epoch 3 <------\n",
      "    Train RMSE loss: 14.113158226013184\n",
      "    Val   RMSE loss: 15.47895622253418\n",
      "\n",
      "------> Epoch 4 <------\n",
      "    Train RMSE loss: 14.083061218261719\n",
      "    Val   RMSE loss: 15.45009994506836\n",
      "\n",
      "------> Epoch 5 <------\n",
      "    Train RMSE loss: 14.05765151977539\n",
      "    Val   RMSE loss: 15.367844581604004\n",
      "\n",
      "------> Epoch 6 <------\n",
      "    Train RMSE loss: 13.992067337036133\n",
      "    Val   RMSE loss: 15.346684455871582\n",
      "\n",
      "------> Epoch 7 <------\n",
      "    Train RMSE loss: 13.944612503051758\n",
      "    Val   RMSE loss: 15.32274055480957\n",
      "\n",
      "------> Epoch 8 <------\n",
      "    Train RMSE loss: 13.883169174194336\n",
      "    Val   RMSE loss: 15.29275894165039\n",
      "\n",
      "------> Epoch 9 <------\n",
      "    Train RMSE loss: 13.801652908325195\n",
      "    Val   RMSE loss: 15.26380729675293\n",
      "\n",
      "------> Epoch 10 <------\n",
      "    Train RMSE loss: 13.79898738861084\n",
      "    Val   RMSE loss: 15.261756896972656\n",
      "\n",
      "------> Epoch 11 <------\n",
      "    Train RMSE loss: 13.702644348144531\n",
      "    Val   RMSE loss: 15.202545166015625\n",
      "\n",
      "------> Epoch 12 <------\n",
      "    Train RMSE loss: 13.70533275604248\n",
      "    Val   RMSE loss: 15.123884201049805\n",
      "\n",
      "------> Epoch 13 <------\n",
      "    Train RMSE loss: 13.526601791381836\n",
      "    Val   RMSE loss: 14.810242652893066\n",
      "\n",
      "------> Epoch 14 <------\n",
      "    Train RMSE loss: 13.330504417419434\n",
      "    Val   RMSE loss: 15.164447784423828\n",
      "\n",
      "------> Epoch 15 <------\n",
      "    Train RMSE loss: 13.313901901245117\n",
      "    Val   RMSE loss: 15.363821029663086\n",
      "\n",
      "------> Epoch 16 <------\n",
      "    Train RMSE loss: 13.069536209106445\n",
      "    Val   RMSE loss: 15.346029281616211\n",
      "\n",
      "------> Epoch 17 <------\n",
      "    Train RMSE loss: 12.677580833435059\n",
      "    Val   RMSE loss: 15.521299362182617\n",
      "\n",
      "------> Epoch 18 <------\n",
      "    Train RMSE loss: 12.38819408416748\n",
      "    Val   RMSE loss: 15.657649993896484\n",
      "\n",
      "------> Epoch 19 <------\n",
      "    Train RMSE loss: 12.077707290649414\n",
      "    Val   RMSE loss: 15.880367279052734\n",
      "\n",
      "------> Epoch 20 <------\n",
      "    Train RMSE loss: 11.629404067993164\n",
      "    Val   RMSE loss: 16.138057708740234\n",
      "\n",
      "\n",
      "****************** Finished Training ******************\n",
      "seconds elapsed:  140.04753875732422\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "epocs = 20\n",
    "rmse = {\"train\": [], \"val\": []}\n",
    "\n",
    "start = time()\n",
    "for epoch in range(epocs):\n",
    "    model.train()\n",
    "    rmse[\"train\"].append(0)\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, var_and_cor, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs, var_and_cor)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        rmse[\"train\"][epoch] += loss.sqrt().mean(dim=0)/len(train_dataloader)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "\n",
    "    rmse[\"val\"].append(0)\n",
    "    for i, data in enumerate(val_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, var_and_cor, labels = data\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs, var_and_cor, predict_anyway=True)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        rmse[\"val\"][epoch] += criterion(outputs, labels).sqrt().mean(dim=0)/len(val_dataloader)\n",
    "    print(f\"\\n------> Epoch {epoch+1} <------\\n    Train RMSE loss: {rmse['train'][epoch]}\\n    Val   RMSE loss: {rmse['val'][epoch]}\")\n",
    "\n",
    "print('\\n\\n****************** Finished Training ******************')\n",
    "print(\"seconds elapsed: \", time()-start)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 115, 116])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 51
    }
   ],
   "source": [
    "inputs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(rmse[\"train\"])), rmse[\"train\"], color=\"blue\", label=\"train\")\n",
    "plt.plot(range(len(rmse[\"val\"])), rmse[\"val\"], color=\"red\", label=\"validation\")\n",
    "plt.title(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "train_embedding = model.forward(torch.Tensor(train_timeseries))\n",
    "val_embedding = model.forward(torch.Tensor(val_timeseries))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "train_embedding_df = pd.concat([train_split.iloc[:, 2:4], pd.DataFrame(train_embedding.detach().numpy(), index=train_split.index)], axis=1)\n",
    "val_embedding_df = pd.concat([val_split.iloc[:, 2:4], pd.DataFrame(val_embedding.detach().numpy(), index=val_split.index)], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "train_embedding_df.var2 = train_embedding_df.var2.replace({\"A\": 0, \"C\": 1})\n",
    "val_embedding_df.var2 = val_embedding_df.var2.replace({\"A\": 0, \"C\": 1})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "X_train, X_val = train_embedding_df.to_numpy(), val_embedding_df.to_numpy()\n",
    "y_train, y_val = train_split.y.to_numpy(), val_split.y.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "data": {
      "text/plain": "SVR(C=0.5, degree=4, kernel='sigmoid')"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = svm.SVR(shrinking=True, kernel=\"sigmoid\", gamma=\"scale\", degree=4, C=0.5)\n",
    "\n",
    "svm_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "y_ped_train = svm_model.predict(X_train)\n",
    "y_ped_val = svm_model.predict(X_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 14.46731332919218 \n",
      "val  : 16.120551887566872\n"
     ]
    }
   ],
   "source": [
    "print(f\"train : {np.sqrt(mean_squared_error(y_ped_train, y_train))} \\nval  : {np.sqrt(mean_squared_error(y_ped_val, y_val))}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "           0    1          2         3          4    5          6          7   \\\n110  0.000000  0.0  33.637390  0.000000  33.896420  0.0  30.615675  31.881088   \n419  0.000000  0.0  33.666306  0.000000  33.922497  0.0  30.645451  31.905592   \n565  0.000000  0.0  33.663048  0.000000  33.919193  0.0  30.641996  31.902082   \n77   0.000000  0.0  25.453283  0.000000  26.474634  0.0  23.194553  24.252129   \n181  0.000000  0.0  33.622978  0.000000  33.884037  0.0  30.611977  31.857613   \n..        ...  ...        ...       ...        ...  ...        ...        ...   \n399  0.000000  0.0  33.666332  0.000000  33.922523  0.0  30.645472  31.905622   \n340  0.000000  0.0  33.666298  0.000000  33.922527  0.0  30.645456  31.905621   \n148  0.042667  0.0  32.572865  0.100658  32.659508  0.0  29.666977  30.599995   \n494  0.000000  0.0  33.655487  0.000000  33.915691  0.0  30.638044  31.897831   \n439  0.000000  0.0  33.666225  0.000000  33.922428  0.0  30.645372  31.905540   \n\n            8    9   ...         22      23         24   25         26  \\\n110  31.626308  0.0  ...  28.560516  0.0000  33.136833  0.0  30.388554   \n419  31.652485  0.0  ...  28.585737  0.0000  33.165642  0.0  30.417480   \n565  31.648861  0.0  ...  28.582979  0.0000  33.162563  0.0  30.414177   \n77   24.933500  0.0  ...  21.665619  0.2713  25.743305  0.0  22.891548   \n181  31.602100  0.0  ...  28.555353  0.0000  33.120586  0.0  30.365826   \n..         ...  ...  ...        ...     ...        ...  ...        ...   \n399  31.652496  0.0  ...  28.585690  0.0000  33.165638  0.0  30.417484   \n340  31.652515  0.0  ...  28.585758  0.0000  33.165642  0.0  30.417496   \n148  30.702549  0.0  ...  27.752827  0.0000  32.023682  0.0  29.502060   \n494  31.643623  0.0  ...  28.577787  0.0000  33.156681  0.0  30.407158   \n439  31.652405  0.0  ...  28.585634  0.0000  33.165539  0.0  30.417383   \n\n            27         28         29   30        31  \n110  31.317009  30.641258  29.553339  0.0  0.000000  \n419  31.347656  30.668304  29.575769  0.0  0.000000  \n565  31.344082  30.664511  29.572756  0.0  0.000000  \n77   24.141226  23.771708  22.632118  0.0  0.032363  \n181  31.302959  30.623489  29.535894  0.0  0.000000  \n..         ...        ...        ...  ...       ...  \n399  31.347687  30.668293  29.575781  0.0  0.000000  \n340  31.347713  30.668343  29.575809  0.0  0.000000  \n148  30.236879  29.531418  28.562664  0.0  0.000000  \n494  31.340368  30.659786  29.570171  0.0  0.000000  \n439  31.347620  30.668217  29.575720  0.0  0.000000  \n\n[120 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>110</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>33.637390</td>\n      <td>0.000000</td>\n      <td>33.896420</td>\n      <td>0.0</td>\n      <td>30.615675</td>\n      <td>31.881088</td>\n      <td>31.626308</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>28.560516</td>\n      <td>0.0000</td>\n      <td>33.136833</td>\n      <td>0.0</td>\n      <td>30.388554</td>\n      <td>31.317009</td>\n      <td>30.641258</td>\n      <td>29.553339</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>419</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>33.666306</td>\n      <td>0.000000</td>\n      <td>33.922497</td>\n      <td>0.0</td>\n      <td>30.645451</td>\n      <td>31.905592</td>\n      <td>31.652485</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>28.585737</td>\n      <td>0.0000</td>\n      <td>33.165642</td>\n      <td>0.0</td>\n      <td>30.417480</td>\n      <td>31.347656</td>\n      <td>30.668304</td>\n      <td>29.575769</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>33.663048</td>\n      <td>0.000000</td>\n      <td>33.919193</td>\n      <td>0.0</td>\n      <td>30.641996</td>\n      <td>31.902082</td>\n      <td>31.648861</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>28.582979</td>\n      <td>0.0000</td>\n      <td>33.162563</td>\n      <td>0.0</td>\n      <td>30.414177</td>\n      <td>31.344082</td>\n      <td>30.664511</td>\n      <td>29.572756</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>25.453283</td>\n      <td>0.000000</td>\n      <td>26.474634</td>\n      <td>0.0</td>\n      <td>23.194553</td>\n      <td>24.252129</td>\n      <td>24.933500</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>21.665619</td>\n      <td>0.2713</td>\n      <td>25.743305</td>\n      <td>0.0</td>\n      <td>22.891548</td>\n      <td>24.141226</td>\n      <td>23.771708</td>\n      <td>22.632118</td>\n      <td>0.0</td>\n      <td>0.032363</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>33.622978</td>\n      <td>0.000000</td>\n      <td>33.884037</td>\n      <td>0.0</td>\n      <td>30.611977</td>\n      <td>31.857613</td>\n      <td>31.602100</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>28.555353</td>\n      <td>0.0000</td>\n      <td>33.120586</td>\n      <td>0.0</td>\n      <td>30.365826</td>\n      <td>31.302959</td>\n      <td>30.623489</td>\n      <td>29.535894</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>33.666332</td>\n      <td>0.000000</td>\n      <td>33.922523</td>\n      <td>0.0</td>\n      <td>30.645472</td>\n      <td>31.905622</td>\n      <td>31.652496</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>28.585690</td>\n      <td>0.0000</td>\n      <td>33.165638</td>\n      <td>0.0</td>\n      <td>30.417484</td>\n      <td>31.347687</td>\n      <td>30.668293</td>\n      <td>29.575781</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>33.666298</td>\n      <td>0.000000</td>\n      <td>33.922527</td>\n      <td>0.0</td>\n      <td>30.645456</td>\n      <td>31.905621</td>\n      <td>31.652515</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>28.585758</td>\n      <td>0.0000</td>\n      <td>33.165642</td>\n      <td>0.0</td>\n      <td>30.417496</td>\n      <td>31.347713</td>\n      <td>30.668343</td>\n      <td>29.575809</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>0.042667</td>\n      <td>0.0</td>\n      <td>32.572865</td>\n      <td>0.100658</td>\n      <td>32.659508</td>\n      <td>0.0</td>\n      <td>29.666977</td>\n      <td>30.599995</td>\n      <td>30.702549</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>27.752827</td>\n      <td>0.0000</td>\n      <td>32.023682</td>\n      <td>0.0</td>\n      <td>29.502060</td>\n      <td>30.236879</td>\n      <td>29.531418</td>\n      <td>28.562664</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>494</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>33.655487</td>\n      <td>0.000000</td>\n      <td>33.915691</td>\n      <td>0.0</td>\n      <td>30.638044</td>\n      <td>31.897831</td>\n      <td>31.643623</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>28.577787</td>\n      <td>0.0000</td>\n      <td>33.156681</td>\n      <td>0.0</td>\n      <td>30.407158</td>\n      <td>31.340368</td>\n      <td>30.659786</td>\n      <td>29.570171</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>439</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>33.666225</td>\n      <td>0.000000</td>\n      <td>33.922428</td>\n      <td>0.0</td>\n      <td>30.645372</td>\n      <td>31.905540</td>\n      <td>31.652405</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>28.585634</td>\n      <td>0.0000</td>\n      <td>33.165539</td>\n      <td>0.0</td>\n      <td>30.417383</td>\n      <td>31.347620</td>\n      <td>30.668217</td>\n      <td>29.575720</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows  32 columns</p>\n</div>"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(val_embedding.detach().numpy(), index=val_split.index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "test = pd.read_csv(join(data_path, 'test.csv'))\n",
    "time_series_test = test.apply(lambda row: get_data(row)[-1], axis=1).to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "predictions = model.forward(torch.Tensor(time_series_test), predict_anyway=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "test_embedding_df = pd.concat([test.iloc[:, 2:4], pd.DataFrame(test_embedding.detach().numpy(), index=test.index)], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[106.7174],\n        [106.8461],\n        [106.8462],\n        [ 40.6383],\n        [106.8414],\n        [106.8447],\n        [106.8461],\n        [ 97.3616],\n        [ 35.5079],\n        [106.8461],\n        [ 93.9863],\n        [106.8318],\n        [-39.6860],\n        [106.8460],\n        [106.8461],\n        [106.8429],\n        [106.8459],\n        [106.8445],\n        [106.8419],\n        [-19.4348],\n        [106.8454],\n        [106.8446],\n        [106.8400],\n        [106.8461],\n        [106.8461],\n        [106.8448],\n        [-38.0568],\n        [106.6906],\n        [106.8460],\n        [106.8461],\n        [106.8459],\n        [ 97.5422],\n        [ 21.0665],\n        [106.8434],\n        [106.8444],\n        [106.8461],\n        [101.3131],\n        [106.8457],\n        [106.8461],\n        [106.8458],\n        [106.8461],\n        [106.8453],\n        [106.8457],\n        [106.8460],\n        [106.8461],\n        [106.8441],\n        [ 14.8656],\n        [106.3747],\n        [ 20.8572],\n        [106.8396],\n        [106.8461],\n        [106.8460],\n        [106.8441],\n        [106.8443],\n        [106.8458],\n        [106.8461],\n        [106.8451],\n        [ 98.0887],\n        [ 63.8200],\n        [106.8455],\n        [ 61.1476],\n        [106.8453],\n        [106.8461],\n        [106.8459],\n        [106.8459],\n        [ 27.2343],\n        [106.8430],\n        [106.8449],\n        [-31.3093],\n        [106.8461],\n        [106.8457],\n        [106.8461],\n        [106.8461],\n        [106.8461],\n        [106.8461],\n        [106.8417],\n        [106.8452],\n        [106.8461],\n        [106.8460],\n        [106.8461],\n        [106.8458],\n        [106.8461],\n        [106.8460],\n        [106.8461],\n        [  7.5869],\n        [106.8460],\n        [ 91.2791],\n        [106.8087],\n        [106.8461],\n        [106.8461],\n        [106.8460],\n        [106.8460],\n        [ 58.7769],\n        [106.8462],\n        [106.8455],\n        [106.8460],\n        [106.8461],\n        [106.8461],\n        [106.8461],\n        [ 33.7541],\n        [ -4.9137],\n        [106.8460],\n        [106.8461],\n        [106.8461],\n        [ 54.4752],\n        [106.8461],\n        [ 87.6812],\n        [106.8459],\n        [106.8461],\n        [106.8461],\n        [106.8459],\n        [ 47.6056],\n        [106.8449],\n        [106.8459],\n        [106.8461],\n        [106.8461],\n        [106.8461],\n        [105.0062],\n        [106.8458],\n        [106.8461]], grad_fn=<AddmmBackward>)"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "y_ped_val = model.forward(torch.Tensor(val_timeseries), predict_anyway=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-259008c8",
   "language": "python",
   "display_name": "PyCharm (NBD-Labwork)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28.082509,
   "end_time": "2021-06-28T09:53:45.178880",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-28T09:53:17.096371",
   "version": "2.3.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}